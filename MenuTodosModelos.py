#----------- Librer√≠as a Usar ------------------
import polars as pl
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error
from sklearn.metrics import accuracy_score, precision_score, recall_score, ConfusionMatrixDisplay
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler, OneHotEncoder
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.linear_model import LinearRegression
from sklearn.neighbors import KNeighborsClassifier
from sklearn.tree import DecisionTreeRegressor, plot_tree
from sklearn.ensemble import RandomForestRegressor
from sklearn.neural_network import MLPRegressor 
import warnings
import sys
import io

# Configurar encoding UTF-8 para Windows
if sys.platform == 'win32':
    sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8', errors='replace')

warnings.filterwarnings('ignore')

# Configuraci√≥n de visualizaci√≥n
try:
    plt.style.use('seaborn-v0_8-darkgrid')
except:
    plt.style.use('seaborn-darkgrid')
sns.set_palette("husl")


#----------- Variables Globales para Modelo Linear Regression ------------------
modeloLinear = None
x_test_linear = None
y_test_linear = None
predic_linear = None
comuna_cols = None
data_linear = None


#----------- Variables Globales para Modelo KNN ------------------
knn_model = None
X_test_knn = None
y_test_knn = None
y_pred_knn = None
knn_metrics = None
umbral_precio = None


#----------- Variables Globales para Modelos de √Årboles ------------------
tree_sin_reg = None
tree_con_reg = None
forest_model = None
X_test_trees = None
y_test_trees = None
y_pred_sin_reg = None
y_pred_con_reg = None
y_pred_forest = None
feature_names_trees = None
X_simple_trees = None
y_simple_trees = None

#----------- Variables Globales para Red Neuronal (MLP) ------------------
modelo_nn = None
scaler_nn = None
comuna_cols_nn = None
x_test_nn = None
y_test_nn = None
predic_nn = None
metrics_nn = {}


def cargar_y_entrenar_modelo_linear():
    """Carga los datos, entrena el modelo Linear Regression y lo deja listo para usar"""
    global modeloLinear, x_test_linear, y_test_linear, predic_linear, comuna_cols, data_linear
    
    print("\nüîÑ Cargando datos y entrenando modelo Linear Regression...")
    
    #----------- Datos del Csv ------------------
    dt = pl.read_csv("DatosRevisadosLimpios.csv")
    data_linear = pl.DataFrame(dt)
    
    #----------- Crear columnas para todas las comunas ------------------
    data_linear = data_linear.to_dummies(columns=["Comuna"])
    comuna_cols = [col for col in data_linear.columns if col.startswith("Comuna_")]
    
    #----------- Extracci√≥n De Datos por columnas ------------------
    xx = data_linear.select([
        "Gastos_Comunes ($)",
        "Metros (m¬≤)",
        "Habitaciones",
        "Ba√±os",
        *[col for col in data_linear.columns if col.startswith("Comuna_")]
    ]).to_numpy()
    
    yy = data_linear.select(pl.col("Precio ($)")).to_numpy().ravel()
    
    #----------- Divisi√≥n y entrenamiento de datos ------------------
    x_train, x_test_linear, y_train, y_test_linear = train_test_split(xx, yy, test_size=0.3, random_state=42)
    
    #----------- Modelo y entrenamiento ------------------
    modeloLinear = LinearRegression()
    modeloLinear.fit(x_train, y_train)
    
    #----------- Predicci√≥n usando Modelo ------------------
    predic_linear = modeloLinear.predict(x_test_linear)
    
    print("‚úÖ Modelo Linear Regression entrenado exitosamente!\n")


def cargar_y_entrenar_modelo_knn():
    """Carga los datos, entrena el modelo KNN y lo deja listo para usar"""
    global knn_model, X_test_knn, y_test_knn, y_pred_knn, knn_metrics, umbral_precio
    
    print("\nüîÑ Cargando datos y entrenando modelo KNN...")
    
    # 1. Cargar datos con Polars
    df = pl.read_csv("DatosRevisadosLimpios.csv")
    
    # 2. Renombrar columnas
    df = df.rename({
        'Precio ($)': 'Precio',
        'Metros (m¬≤)': 'MetrosCuadrados',
        'Gastos_Comunes ($)': 'GastosComunes'
    })
    
    # 3. Seleccionar columnas relevantes y eliminar nulos
    df = df.select(['Precio', 'MetrosCuadrados', 'Comuna', 'Ba√±os', 'Habitaciones', 'GastosComunes']).drop_nulls()
    
    # 4. Crear variable binaria de "Arriendo alto"
    umbral_precio = df['Precio'].median()
    df = df.with_columns([
        (df['Precio'] > umbral_precio).cast(pl.Int8).alias('ArriendoAlto')
    ])
    
    # 5. Convertir a pandas (para sklearn)
    df_pd = df.to_pandas()
    
    # 6. Separar X e y
    X = df_pd[['MetrosCuadrados', 'Comuna', 'Ba√±os', 'Habitaciones', 'GastosComunes']]
    y = df_pd['ArriendoAlto']
    
    # 7. Divisi√≥n entrenamiento/prueba
    X_train, X_test_knn, y_train, y_test_knn = train_test_split(
        X, y, test_size=0.2, random_state=42, stratify=y
    )
    
    # 8. Preprocesamiento (escalar + codificar)
    num_cols = ['MetrosCuadrados', 'Ba√±os', 'Habitaciones', 'GastosComunes']
    cat_cols = ['Comuna']
    
    preprocessor = ColumnTransformer([
        ('num', StandardScaler(), num_cols),
        ('cat', OneHotEncoder(handle_unknown='ignore'), cat_cols)
    ])
    
    # 9. Modelo KNN
    knn_model = Pipeline(steps=[
        ('preprocessor', preprocessor),
        ('classifier', KNeighborsClassifier(n_neighbors=5))
    ])
    
    knn_model.fit(X_train, y_train)
    y_pred_knn = knn_model.predict(X_test_knn)
    
    # 10. Calcular m√©tricas
    knn_metrics = {
        'Accuracy': accuracy_score(y_test_knn, y_pred_knn),
        'Precision': precision_score(y_test_knn, y_pred_knn),
        'Recall': recall_score(y_test_knn, y_pred_knn)
    }
    
    print(f"‚úÖ Modelo KNN entrenado exitosamente!")
    print(f"üìä Umbral de precio (mediana): ${umbral_precio:,.0f}\n")


def cargar_y_entrenar_modelos_arboles():
    """Carga los datos, entrena los modelos de √°rboles (sin reg, con reg, Random Forest)"""
    global tree_sin_reg, tree_con_reg, forest_model
    global X_test_trees, y_test_trees
    global y_pred_sin_reg, y_pred_con_reg, y_pred_forest
    global feature_names_trees, X_simple_trees, y_simple_trees
    
    print("\nüîÑ Cargando datos y entrenando modelos de √Årboles de Decisi√≥n...")
    
    # Cargar datos
    df = pd.read_csv("DatosRevisadosLimpios.csv")
    
    # Renombrar columnas
    df = df.rename(columns={
        'Precio ($)': 'Precio',
        'Metros (m¬≤)': 'MetrosCuadrados',
        'Gastos_Comunes ($)': 'GastosComunes'
    })
    
    # Seleccionar columnas relevantes
    df = df[['Precio', 'MetrosCuadrados', 'Comuna', 'Ba√±os', 'Habitaciones', 'GastosComunes']].dropna()
    
    # Separar variables
    X = df[['MetrosCuadrados', 'Comuna', 'Ba√±os', 'Habitaciones', 'GastosComunes']]
    y = df['Precio']
    
    # Divisi√≥n entrenamiento/prueba
    X_train, X_test_trees, y_train, y_test_trees = train_test_split(X, y, test_size=0.3, random_state=42)
    
    # Preprocesamiento
    num_cols = ['MetrosCuadrados', 'Ba√±os', 'Habitaciones', 'GastosComunes']
    cat_cols = ['Comuna']
    
    preprocessor = ColumnTransformer([
        ('num', StandardScaler(), num_cols),
        ('cat', OneHotEncoder(handle_unknown='ignore', sparse_output=False), cat_cols)
    ])
    
    # 1. √Årbol SIN regularizaci√≥n
    print("   üå≥ Entrenando √Årbol SIN regularizaci√≥n...")
    tree_sin_reg = Pipeline(steps=[
        ('preprocessor', preprocessor),
        ('regressor', DecisionTreeRegressor(
            max_depth=None,
            min_samples_leaf=1,
            random_state=42
        ))
    ])
    tree_sin_reg.fit(X_train, y_train)
    y_pred_sin_reg = tree_sin_reg.predict(X_test_trees)
    
    # 2. √Årbol CON regularizaci√≥n
    print("   üå≥ Entrenando √Årbol CON regularizaci√≥n...")
    tree_con_reg = Pipeline(steps=[
        ('preprocessor', preprocessor),
        ('regressor', DecisionTreeRegressor(
            max_depth=5,
            min_samples_leaf=10,
            random_state=42
        ))
    ])
    tree_con_reg.fit(X_train, y_train)
    y_pred_con_reg = tree_con_reg.predict(X_test_trees)
    
    # 3. Random Forest
    print("   üå≤ Entrenando Random Forest (100 √°rboles)...")
    forest_model = Pipeline(steps=[
        ('preprocessor', preprocessor),
        ('regressor', RandomForestRegressor(
            n_estimators=100,
            max_depth=10,
            min_samples_leaf=5,
            random_state=42,
            n_jobs=-1
        ))
    ])
    forest_model.fit(X_train, y_train)
    y_pred_forest = forest_model.predict(X_test_trees)
    
    # Preparar datos para visualizaci√≥n del √°rbol
    X_simple_trees = X.copy()
    X_simple_trees = pd.get_dummies(X_simple_trees, columns=['Comuna'], drop_first=False, prefix='Comuna')
    y_simple_trees = y
    
    # Nombres de caracter√≠sticas para importancia
    encoder = forest_model.named_steps['preprocessor'].named_transformers_['cat']
    encoded_cols = list(encoder.get_feature_names_out(cat_cols))
    feature_names_trees = num_cols + encoded_cols
    
    print("‚úÖ Modelos de √Årboles entrenados exitosamente!\n")


def cargar_y_entrenar_modelo_red_neuronal():
    """Carga datos filtrados, entrena el MLP Regressor y lo guarda globalmente."""
    global modelo_nn, scaler_nn, comuna_cols_nn, x_test_nn, y_test_nn, predic_nn, metrics_nn
    
    print("\nüîÑ Cargando datos y entrenando modelo Red Neuronal (MLP)...")
    
    #----------- Cargar Datos ------------------
    dt = pl.read_csv("DatosRevisadosLimpios.csv")
    data = pl.DataFrame(dt)

    #----------- Filtro para acotar los datos ------------------
    data = data.filter(
        (pl.col("Precio ($)") >= 100000) &
        (pl.col("Precio ($)") <= 2000000) &
        (pl.col("Metros (m¬≤)") >= 15) &
        (pl.col("Metros (m¬≤)") <= 200)
    )

    #----------- Crear columnas para todas las comunas ------------------
    data = data.to_dummies(columns=["Comuna"]) 
    comuna_cols_nn = [col for col in data.columns if col.startswith("Comuna_")] # Guardar comunas espec√≠ficas de este modelo


    #----------- Selecci√≥n De Variables ------------------
    xx = data.select([
        "Gastos_Comunes ($)",
        "Metros (m¬≤)",
        "Habitaciones",
        "Ba√±os",
        *[col for col in data.columns if col.startswith("Comuna_")]
    ]).to_numpy()

    yy = data.select(pl.col("Precio ($)")).to_numpy().ravel()

    #----------- Separar y entrenar los datos ------------------
    x_train, x_test_nn, y_train, y_test_nn = train_test_split(xx, yy, test_size=0.3, random_state=42)

    #----------- Escalado de Datos ------------------
    scaler_nn = StandardScaler()
    x_train_scaled = scaler_nn.fit_transform(x_train)
    x_test_scaled = scaler_nn.transform(x_test_nn)

    #----------- Crear y definir par√°metros en Red Neuronal ------------------
    modelo_nn = MLPRegressor(
        hidden_layer_sizes=(40, 20),   # Capas Ocultas (Dos Capas) -> 40 y 20 neuronas
        activation='relu',             # Funci√≥n de activaci√≥n moderna relu
        max_iter=7000,                 # N¬∞ De Iteraciones
        random_state=42,
        early_stopping=True,           # A√±adido para evitar sobreajuste y acortar entrenamiento
        n_iter_no_change=50
    )
    
    print("   üß† Entrenando MLP Regressor (puede tomar un momento)...")
    #----------- Entrenamiento De Datos ------------------
    modelo_nn.fit(x_train_scaled, y_train)

    #----------- Metricas Arrojadas (Evaluaci√≥n) ------------------
    predic_nn = modelo_nn.predict(x_test_scaled)
    
    metrics_nn['R2'] = r2_score(y_test_nn, predic_nn)
    metrics_nn['MSE'] = mean_squared_error(y_test_nn, predic_nn)
    metrics_nn['MAE'] = mean_absolute_error(y_test_nn, predic_nn)
    metrics_nn['RMSE'] = np.sqrt(mean_squared_error(y_test_nn, predic_nn))
    
    print(f"‚úÖ Modelo Red Neuronal entrenado exitosamente!")
    print(f"   R¬≤ -> {metrics_nn['R2']:.4f}")
    print(f"   MAE -> ${metrics_nn['MAE']:,.0f}\n")


def accion1():
    """Predecir precio de arriendo con Linear Regression"""
    global modeloLinear, comuna_cols
    
    if modeloLinear is None:
        print("\n‚ö†Ô∏è  El modelo Linear Regression a√∫n no ha sido entrenado.")
        cargar_y_entrenar_modelo_linear()
    
    print("\n=========== PREDICCI√ìN DE PRECIO DE ARRIENDO (LINEAR REGRESSION) ===========")
    
    try:
        gastosComun = int(input("\nIngrese gastos comunes aproximados -> $"))
        metrosC = int(input("Ingrese metros cuadrados del arriendo -> "))
        habitaciones = int(input("Ingrese las habitaciones para el arriendo -> "))
        ba√±os = int(input("Ingrese los ba√±os para el arriendo -> "))
        comuna = input("Ingrese la comuna -> ").strip().title()
        
        comuna_dummies = [1 if col == f"Comuna_{comuna}" else 0 for col in comuna_cols]
        
        if sum(comuna_dummies) == 0: 
            print(f"\n‚ö†Ô∏è  Advertencia: la comuna '{comuna}' no existe en los datos. Se asumir√° base (todas 0).")
        
        predikkk = [gastosComun, metrosC, habitaciones, ba√±os] + comuna_dummies
        
        ff = modeloLinear.predict([predikkk])
        print(f"\nüí∞ Su arriendo en {comuna} tendr√° el valor de -> ${round(ff[0], 0):,.0f}")
        
    except ValueError:
        print("\n‚ùå Error: Debe ingresar valores num√©ricos v√°lidos.")
    except Exception as e:
        print(f"\n‚ùå Error inesperado: {e}")


def accion2():
    """Clasificar arriendo como ALTO o BAJO con KNN"""
    global knn_model, umbral_precio
    
    if knn_model is None:
        print("\n‚ö†Ô∏è  El modelo KNN a√∫n no ha sido entrenado.")
        cargar_y_entrenar_modelo_knn()
    
    print("\n=========== CLASIFICACI√ìN DE ARRIENDO (KNN) ===========")
    print(f"üìä Umbral de precio (mediana): ${umbral_precio:,.0f}")
    print("    ‚Ä¢ Arriendo ALTO: mayor a este valor")
    print("    ‚Ä¢ Arriendo BAJO: menor o igual a este valor\n")
    
    try:
        metros = float(input("Metros cuadrados: "))
        banos = int(input("N√∫mero de ba√±os: "))
        habs = int(input("N√∫mero de habitaciones: "))
        gastos = float(input("Gastos comunes ($): "))
        comuna = input("Nombre de la comuna: ").strip().title()
        
        nuevo_dato = pd.DataFrame([{
            'MetrosCuadrados': metros,
            'Comuna': comuna,
            'Ba√±os': banos,
            'Habitaciones': habs,
            'GastosComunes': gastos
        }])
        
        prediccion = knn_model.predict(nuevo_dato)[0]
        
        print("\nüîé Resultado del modelo KNN:")
        if prediccion == 1:
            print("‚û°Ô∏è  El modelo predice que el arriendo ser√≠a ALTO üí∞")
            print(f"    (Precio estimado mayor a ${umbral_precio:,.0f})")
        else:
            print("‚û°Ô∏è  El modelo predice que el arriendo ser√≠a BAJO üè°")
            print(f"    (Precio estimado menor o igual a ${umbral_precio:,.0f})")
    
    except Exception as e:
        print(f"\n‚ö†Ô∏è Error al ingresar o procesar los datos: {e}")


def accion3():
    """Predecir precio con modelos de √°rboles (Decision Tree y Random Forest)"""
    global tree_sin_reg, tree_con_reg, forest_model
    
    if forest_model is None:
        print("\n‚ö†Ô∏è  Los modelos de √Årboles a√∫n no han sido entrenados.")
        cargar_y_entrenar_modelos_arboles()
    
    print("\n=========== PREDICCI√ìN CON √ÅRBOLES DE DECISI√ìN Y RANDOM FOREST ===========")
    
    try:
        metrosC = float(input("\nMetros cuadrados: "))
        comuna = input("Nombre de la comuna: ").strip().title()
        ba√±os = int(input("N√∫mero de ba√±os: "))
        habitaciones = int(input("N√∫mero de habitaciones: "))
        gastosComun = float(input("Gastos comunes ($): "))
        
        nuevo_dato = pd.DataFrame([{
            'MetrosCuadrados': metrosC,
            'Comuna': comuna,
            'Ba√±os': ba√±os,
            'Habitaciones': habitaciones,
            'GastosComunes': gastosComun
        }])
        
        # Predicciones
        pred_sin_reg = tree_sin_reg.predict(nuevo_dato)[0]
        pred_con_reg = tree_con_reg.predict(nuevo_dato)[0]
        pred_forest = forest_model.predict(nuevo_dato)[0]
        
        print("\nüìä RESULTADOS DE PREDICCI√ìN:")
        print(f"\nüå≥ √Årbol SIN Regularizaci√≥n: ${pred_sin_reg:,.0f}")
        print(f"   (Puede tener sobreajuste - memoriza datos)")
        
        print(f"\nüå≥ √Årbol CON Regularizaci√≥n: ${pred_con_reg:,.0f}")
        print(f"   (Mejor balance - m√°s confiable)")
        
        print(f"\nüå≤ Random Forest (100 √°rboles): ${pred_forest:,.0f}")
        print(f"   (M√°s robusto - recomendado)")
        
        print(f"\nüí° Recomendaci√≥n: Usar el valor de Random Forest (${pred_forest:,.0f})")
        
    except Exception as e:
        print(f"\n‚ö†Ô∏è Error al ingresar o procesar los datos: {e}")

def accion4_predecir_nn():
    """Predecir precio con Red Neuronal (MLP)"""
    global modelo_nn, scaler_nn, comuna_cols_nn
    
    if modelo_nn is None:
        print("\n‚ö†Ô∏è  El modelo de Red Neuronal a√∫n no ha sido entrenado.")
        cargar_y_entrenar_modelo_red_neuronal()
    
    print("\n=========== PREDICCI√ìN CON RED NEURONAL (MLP REGRESSOR) ===========")
    print("‚ÑπÔ∏è  Este modelo fue entrenado con datos filtrados:")
    print("   (Precio: $100k-$2M, Metros: 15-200 m¬≤)")
    
    try:
        gastosComun = int(input("\nIngrese gastos comunes aproximados -> $"))
        metrosC = int(input("Ingrese metros cuadrados del arriendo -> "))
        habitaciones = int(input("Ingrese las habitaciones para el arriendo -> "))
        ba√±os = int(input("Ingrese los ba√±os para el arriendo -> "))
        comuna = input("Ingrese la comuna -> ").strip().title()

        # Usar las columnas de comuna espec√≠ficas del modelo NN
        comuna_dummies = [1 if col == f"Comuna_{comuna}" else 0 for col in comuna_cols_nn]

        if sum(comuna_dummies) == 0: 
            print(f"\n‚ö†Ô∏è  Advertencia: la comuna '{comuna}' no existe en los datos de este modelo. Se asumir√° base (todas 0).")

        predikkk = [gastosComun, metrosC, habitaciones, ba√±os] + comuna_dummies
        
        # Escalar los datos con el escalador espec√≠fico del modelo NN
        predikkk_scaled = scaler_nn.transform([predikkk])

        # Prediccion con datos recientes
        ff = modelo_nn.predict(predikkk_scaled)
        print(f"\nüß† Su arriendo en {comuna} tendr√° el valor de -> ${round(ff[0],0):,.0f}")
        
    except ValueError:
        print("\n‚ùå Error: Debe ingresar valores num√©ricos v√°lidos.")
    except Exception as e:
        print(f"\n‚ùå Error inesperado: {e}")


def accion5_mostrar_metricas():
    """Mostrar m√©tricas de todos los modelos"""
    print("\n=========== M√âTRICAS DE TODOS LOS MODELOS ===========")
    
    # M√©tricas Linear Regression
    if predic_linear is None:
        print("\n‚ö†Ô∏è  Entrenando modelo Linear Regression...")
        cargar_y_entrenar_modelo_linear()
    
    print("\nüìà MODELO 1: LINEAR REGRESSION (Predicci√≥n de precio)")
    print(f"   R¬≤ (Coeficiente de determinaci√≥n) -> {r2_score(y_test_linear, predic_linear):.4f}")
    print(f"   MSE (Error cuadr√°tico medio) -> ${mean_squared_error(y_test_linear, predic_linear):,.2f}")
    print(f"   MAE (Error absoluto medio) -> ${mean_absolute_error(y_test_linear, predic_linear):,.2f}")
    print(f"   RMSE (Ra√≠z del error cuadr√°tico medio) -> ${np.sqrt(mean_squared_error(y_test_linear, predic_linear)):,.2f}")
    
    # M√©tricas KNN
    if knn_metrics is None:
        print("\n‚ö†Ô∏è  Entrenando modelo KNN...")
        cargar_y_entrenar_modelo_knn()
    
    print("\nüìä MODELO 2: KNN (Clasificaci√≥n Alto/Bajo)")
    for k, v in knn_metrics.items():
        print(f"   {k} -> {v:.3f}")
    
    # M√©tricas √Årboles
    if forest_model is None:
        print("\n‚ö†Ô∏è  Entrenando modelos de √Årboles...")
        cargar_y_entrenar_modelos_arboles()
    
    print("\nüå≥ MODELO 3: √ÅRBOLES DE DECISI√ìN Y RANDOM FOREST")
    
    # √Årbol sin regularizaci√≥n
    mae_sin = mean_absolute_error(y_test_trees, y_pred_sin_reg)
    r2_sin = r2_score(y_test_trees, y_pred_sin_reg)
    print(f"\n   √Årbol SIN Regularizaci√≥n:")
    print(f"       MAE -> ${mae_sin:,.0f}")
    print(f"       R¬≤ -> {r2_sin:.4f}")
    
    # √Årbol con regularizaci√≥n
    mae_con = mean_absolute_error(y_test_trees, y_pred_con_reg)
    r2_con = r2_score(y_test_trees, y_pred_con_reg)
    print(f"\n   √Årbol CON Regularizaci√≥n:")
    print(f"       MAE -> ${mae_con:,.0f}")
    print(f"       R¬≤ -> {r2_con:.4f}")
    
    # Random Forest
    mae_forest = mean_absolute_error(y_test_trees, y_pred_forest)
    r2_forest = r2_score(y_test_trees, y_pred_forest)
    rmse_forest = np.sqrt(mean_squared_error(y_test_trees, y_pred_forest))
    print(f"\n   Random Forest (100 √°rboles):")
    print(f"       MAE -> ${mae_forest:,.0f}")
    print(f"       RMSE -> ${rmse_forest:,.0f}")
    print(f"       R¬≤ -> {r2_forest:.4f}")

    # M√©tricas Red Neuronal
    if not metrics_nn:
        print("\n‚ö†Ô∏è  Entrenando modelo Red Neuronal...")
        cargar_y_entrenar_modelo_red_neuronal()
        
    print("\nüß† MODELO 4: RED NEURONAL (MLP REGRESSOR)")
    print(f"   Datos filtrados (Precio: $100k-$2M, Metros: 15-200 m¬≤)")
    print(f"   R¬≤ -> {metrics_nn.get('R2', 0):.4f}")
    print(f"   MAE -> ${metrics_nn.get('MAE', 0):,.2f}")
    print(f"   RMSE -> ${metrics_nn.get('RMSE', 0):,.2f}")


def accion6_grafico_lr():
    """Mostrar gr√°ficos de Linear Regression"""
    global y_test_linear, predic_linear
    
    if predic_linear is None:
        print("\n‚ö†Ô∏è  El modelo Linear Regression a√∫n no ha sido entrenado.")
        cargar_y_entrenar_modelo_linear()
    
    print("\nüìä Generando gr√°ficos de Linear Regression...")
    
    plt.figure(figsize=(8, 6))
    plt.scatter(y_test_linear, predic_linear, alpha=0.5)
    plt.plot([y_test_linear.min(), y_test_linear.max()], [y_test_linear.min(), y_test_linear.max()], color='red', linewidth=2)
    plt.xlabel("Precio Real ($)")
    plt.ylabel("Precio Predicho ($)")
    plt.title("Comparaci√≥n entre Precio Real y Precio Predicho (Linear Regression)")
    plt.grid(True)
    plt.show()
    
    residuos = y_test_linear - predic_linear
    
    plt.figure(figsize=(8, 6))
    plt.scatter(predic_linear, residuos, alpha=0.5)
    plt.axhline(0, color='red', linestyle='--')
    plt.xlabel("Precio Predicho ($)")
    plt.ylabel("Error (Residual)")
    plt.title("Distribuci√≥n de Errores del Modelo (Linear Regression)")
    plt.grid(True)
    plt.show()


def accion7_grafico_knn():
    """Mostrar gr√°ficos de KNN"""
    global knn_model, X_test_knn, y_test_knn, knn_metrics
    
    if knn_model is None:
        print("\n‚ö†Ô∏è  El modelo KNN a√∫n no ha sido entrenado.")
        cargar_y_entrenar_modelo_knn()
    
    print("\nüìä Generando gr√°ficos de KNN...")
    
    fig, ax = plt.subplots(figsize=(6, 5))
    ConfusionMatrixDisplay.from_estimator(knn_model, X_test_knn, y_test_knn, ax=ax, cmap='Greens')
    ax.set_title("Matriz de Confusi√≥n - KNN")
    plt.show()
    
    fig, ax = plt.subplots(figsize=(6, 4))
    sns.barplot(x=list(knn_metrics.keys()), y=list(knn_metrics.values()), color="green", ax=ax)
    ax.set_ylim(0, 1)
    ax.set_title("Desempe√±o del Modelo KNN")
    for container in ax.containers:
        ax.bar_label(container, fmt='%.2f', label_type='edge', padding=3)
    plt.show()


def accion8_grafico_arboles():
    """Mostrar gr√°ficos de √Årboles de Decisi√≥n"""
    global tree_sin_reg, tree_con_reg, forest_model
    global y_test_trees, y_pred_sin_reg, y_pred_con_reg, y_pred_forest
    
    if forest_model is None:
        print("\n‚ö†Ô∏è  Los modelos de √Årboles a√∫n no han sido entrenados.")
        cargar_y_entrenar_modelos_arboles()
    
    print("\nüìä Generando gr√°ficos de √Årboles de Decisi√≥n...")
    
    # Comparaci√≥n de los 3 modelos
    fig, axes = plt.subplots(1, 3, figsize=(18, 5))
    
    r2_sin = r2_score(y_test_trees, y_pred_sin_reg)
    r2_con = r2_score(y_test_trees, y_pred_con_reg)
    r2_forest = r2_score(y_test_trees, y_pred_forest)
    
    # √Årbol sin regularizaci√≥n
    axes[0].scatter(y_test_trees, y_pred_sin_reg, alpha=0.4, s=20)
    axes[0].plot([y_test_trees.min(), y_test_trees.max()], [y_test_trees.min(), y_test_trees.max()], 'r--', lw=2)
    axes[0].set_xlabel('Precio Real', fontsize=11)
    axes[0].set_ylabel('Precio Predicho', fontsize=11)
    axes[0].set_title(f'√Årbol SIN Regularizaci√≥n\nR¬≤ = {r2_sin:.3f}', fontsize=12, fontweight='bold')
    axes[0].grid(True, alpha=0.3)
    
    # √Årbol con regularizaci√≥n
    axes[1].scatter(y_test_trees, y_pred_con_reg, alpha=0.4, s=20)
    axes[1].plot([y_test_trees.min(), y_test_trees.max()], [y_test_trees.min(), y_test_trees.max()], 'r--', lw=2)
    axes[1].set_xlabel('Precio Real', fontsize=11)
    axes[1].set_ylabel('Precio Predicho', fontsize=11)
    axes[1].set_title(f'√Årbol CON Regularizaci√≥n\nR¬≤ = {r2_con:.3f}', fontsize=12, fontweight='bold')
    axes[1].grid(True, alpha=0.3)
    
    # Random Forest
    axes[2].scatter(y_test_trees, y_pred_forest, alpha=0.4, s=20)
    axes[2].plot([y_test_trees.min(), y_test_trees.max()], [y_test_trees.min(), y_test_trees.max()], 'r--', lw=2)
    axes[2].set_xlabel('Precio Real', fontsize=11)
    axes[2].set_ylabel('Precio Predicho', fontsize=11)
    axes[2].set_title(f'Random Forest\nR¬≤ = {r2_forest:.3f}', fontsize=12, fontweight='bold')
    axes[2].grid(True, alpha=0.3)
    
    plt.tight_layout()
    plt.show()
    
    # Gr√°fico de m√©tricas comparativas
    mae_sin = mean_absolute_error(y_test_trees, y_pred_sin_reg)
    mae_con = mean_absolute_error(y_test_trees, y_pred_con_reg)
    mae_forest = mean_absolute_error(y_test_trees, y_pred_forest)
    
    comparacion = pd.DataFrame({
        'Modelo': ['√Årbol\n(Sin Reg.)', '√Årbol\n(Con Reg.)', 'Random\nForest'],
        'MAE': [mae_sin, mae_con, mae_forest],
        'R¬≤': [r2_sin, r2_con, r2_forest]
    })
    
    fig, axes = plt.subplots(1, 2, figsize=(14, 6))
    
    axes[0].bar(comparacion['Modelo'], comparacion['MAE'], 
                color=['#e74c3c', '#3498db', '#2ecc71'], alpha=0.8)
    axes[0].set_ylabel('MAE (Error Absoluto Medio)', fontsize=12)
    axes[0].set_title('Comparaci√≥n de MAE\n(Menor es mejor)', fontsize=14, fontweight='bold')
    axes[0].grid(True, alpha=0.3, axis='y')
    for i, v in enumerate(comparacion['MAE']):
        axes[0].text(i, v, f'${v:,.0f}', ha='center', va='bottom', fontsize=10)
    
    axes[1].bar(comparacion['Modelo'], comparacion['R¬≤'], 
                color=['#e74c3c', '#3498db', '#2ecc71'], alpha=0.8)
    axes[1].set_ylabel('R¬≤ (Coeficiente de Determinaci√≥n)', fontsize=12)
    axes[1].set_title('Comparaci√≥n de R¬≤\n(Mayor es mejor)', fontsize=14, fontweight='bold')
    axes[1].set_ylim(0, 1)
    axes[1].grid(True, alpha=0.3, axis='y')
    for i, v in enumerate(comparacion['R¬≤']):
        axes[1].text(i, v, f'{v:.3f}', ha='center', va='bottom', fontsize=10)
    
    plt.tight_layout()
    plt.show()

def accion9_grafico_nn():
    """Mostrar gr√°ficos de Red Neuronal (MLP)"""
    global y_test_nn, predic_nn
    
    if predic_nn is None:
        print("\n‚ö†Ô∏è  El modelo de Red Neuronal a√∫n no ha sido entrenado.")
        cargar_y_entrenar_modelo_red_neuronal()
    
    print("\nüìä Generando gr√°ficos de Red Neuronal (MLP)...")
    
    plt.figure(figsize=(8, 6))
    plt.scatter(y_test_nn, predic_nn, alpha=0.4)
    plt.plot([y_test_nn.min(), y_test_nn.max()], [y_test_nn.min(), y_test_nn.max()], 'r--')
    plt.xlabel("Precio real")
    plt.ylabel("Precio predicho")
    plt.title("Predicho vs Real (Red Neuronal MLP)")
    plt.grid(True)
    plt.show()


def accion10_importancia():
    """Mostrar importancia de variables y estructura del √°rbol"""
    global forest_model, feature_names_trees, X_simple_trees, y_simple_trees
    
    if forest_model is None:
        print("\n‚ö†Ô∏è  Los modelos de √Årboles a√∫n no han sido entrenados.")
        cargar_y_entrenar_modelos_arboles()
    
    print("\nüìä Generando gr√°ficos de Importancia de Variables...")
    
    # Importancia de variables
    rf_regressor = forest_model.named_steps['regressor']
    importances = pd.DataFrame({
        'Variable': feature_names_trees,
        'Importancia': rf_regressor.feature_importances_
    }).sort_values(by='Importancia', ascending=False)
    
    print("\nTOP 10 Variables M√°s Importantes:")
    print(importances.head(10).to_string(index=False))
    
    plt.figure(figsize=(12, 8))
    top_15 = importances.head(15)
    sns.barplot(data=top_15, y='Variable', x='Importancia', palette='viridis')
    plt.title('Importancia de las Variables - Random Forest\n(Top 15)', fontsize=16, fontweight='bold')
    plt.xlabel('Importancia', fontsize=12)
    plt.ylabel('Variable', fontsize=12)
    plt.tight_layout()
    plt.show()
    
    # Estructura del √°rbol
    print("\nüìä Generando visualizaci√≥n de la estructura del √°rbol")
    print("\nüìä Generando visualizaci√≥n de la estructura del √°rbol...")
    
    tree_vis = DecisionTreeRegressor(max_depth=3, min_samples_leaf=20, random_state=42)
    tree_vis.fit(X_simple_trees, y_simple_trees)
    
    plt.figure(figsize=(20, 10))
    plot_tree(tree_vis, feature_names=X_simple_trees.columns, filled=True, fontsize=9, 
              max_depth=3, rounded=True, precision=2)
    plt.title('Estructura de un √Årbol de Decisi√≥n Regularizado\n(max_depth=3, min_samples_leaf=20)', 
              fontsize=16, fontweight='bold', pad=20)
    plt.tight_layout()
    plt.show()


def salir():
    print('\nüëã Saliendo del sistema...')


def mostrar_menu(opciones):
    print('\n' + '='*70)
    print('       SISTEMA COMPLETO DE PREDICCI√ìN Y CLASIFICACI√ìN DE ARRIENDOS')
    print('='*70)
    print('\nSeleccione una opci√≥n:')
    for clave in sorted(opciones, key=int):
        print(f' {clave}) {opciones[clave][0]}')


def leer_opcion(opciones):
    while (a := input('\nOpci√≥n: ')) not in opciones:
        print('‚ùå Opci√≥n incorrecta, vuelva a intentarlo.')
    return a


def ejecutar_opcion(opcion, opciones):
    opciones[opcion][1]()


def generar_menu(opciones, opcion_salida):
    opcion = None
    while opcion != opcion_salida:
        mostrar_menu(opciones)
        opcion = leer_opcion(opciones)
        ejecutar_opcion(opcion, opciones)
        print()


def menu_principal():
    opciones = {
        '1': ('üè† Predecir precio (Linear Regression)', accion1),
        '2': ('üîç Clasificar arriendo ALTO/BAJO (KNN)', accion2),
        '3': ('üå≥ Predecir precio (√Årboles y Random Forest)', accion3),
        '4': ('üß† Predecir precio (Red Neuronal MLP)', accion4_predecir_nn),
        '5': ('üìä Ver m√©tricas de TODOS los modelos', accion5_mostrar_metricas),
        '6': ('üìà Gr√°ficos Linear Regression', accion6_grafico_lr),
        '7': ('üìâ Gr√°ficos KNN', accion7_grafico_knn),
        '8': ('üå≤ Gr√°ficos √Årboles de Decisi√≥n', accion8_grafico_arboles),
        '9': ('üß† Gr√°ficos Red Neuronal', accion9_grafico_nn),
        '10': ('üî¨ Importancia de variables y estructura del √°rbol', accion10_importancia),
        '11': ('üö™ Salir', salir)
    }
    
    generar_menu(opciones, '11')


if __name__ == '__main__':
    print("\n" + "="*70)
    print("   SISTEMA DE MACHINE LEARNING PARA PREDICCI√ìN DE ARRIENDOS")
    print("="*70)
    print("\nüìö MODELOS DISPONIBLES:")
    print("   1Ô∏è‚É£  Linear Regression - Predicci√≥n de precio exacto")
    print("   2Ô∏è‚É£  KNN - Clasificaci√≥n Alto/Bajo")
    print("   3Ô∏è‚É£  √Årboles de Decisi√≥n y Random Forest")
    print("   4Ô∏è‚É£  Red Neuronal (MLP) - Predicci√≥n de precio (con filtros)")
    print("\nüí° Los modelos se entrenan autom√°ticamente al usarlos")
    print("="*70)
    
    menu_principal()